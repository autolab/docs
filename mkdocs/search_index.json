{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the Autolab Docs\n\n\nAutolab is a course management and homework autograding platform that enables instructors to offer programming labs to their students. It includes gradebooks, rosters, handins/handouts, lab writeups, code annotation, manual grading, late penalties, grace days, cheat checking, meetings, partners, and bulk emails.\n\n\nGetting Started\n\n\nFor information on how to use Autolab go to the \ninstructors page\n. To learn how to write an autograded lab go to the \nlab authors page\n\n\nAutolab consists of two services, the Ruby on Rails frontend and \nTango\n, the Python grading server. In order, to use all features\nof Autolab, we highly recommend installing both services.\n\n\nCurrently, we have support for installation on \nUbuntu 14.04+\n and \nMac OSX\n\n\nUbuntu 14.04+\n\n\nThe following command runs a script that installs Autolab and all it's dependancies. You will be prompted for the \nsudo\n password and other confirmations. You can see the details of the script \nhere\n\n\n1\nAUTOLAB_SCRIPT\n=\n`\nmktemp\n`\n \n \n\\c\nurl -sSL https://raw.githubusercontent.com/autolab/Autolab/master/bin/setup.sh \n \n$AUTOLAB_SCRIPT\n \n \n\\b\nash \n$AUTOLAB_SCRIPT\n\n\n\n\n\n\n\nMac OSX\n\n\nFollow the step-by-step instructions below:\n\n\n\n\n\n\nInstall \nrbenv\n (use the Basic GitHub Checkout method)\n\n\n\n\n\n\nInstall \nruby-build\n as an rbenv plugin:\n\n\n1\ngit clone https://github.com/sstephenson/ruby-build.git ~/.rbenv/plugins/ruby-build\n\n\n\n\n\n\nRestart your shell at this point in order to start using your newly installed rbenv\n\n\n\n\n\n\nInstall the correct version of ruby:\n\n\n1\nrbenv install $(cat .ruby-version)\n\n\n\n\n\n\nAt this point, confirm that \nrbenv\n is working (you might need to restart your shell):\n\n\n1\n2\n3\n4\n5\n$ which ruby\n~/.rbenv/shims/ruby\n\n$ which rake\n~/.rbenv/shims/rake\n\n\n\n\n\n\n\n\n\n\nInstall \nbundler\n:\n\n\n1\n2\ngem install bundler\nrbenv rehash\n\n\n\n\n\n\n\n\n\n\nClone the Autolab repo into any desired directory:\n\n\n1\ngit clone https://github.com/autolab/Autolab.git\n\n\n\n\n\n\n\n\n\n\nInstall the required gems (run the following commands in the cloned Autolab repo):\n\n\n1\n2\ncd bin\nbundle install\n\n\n\n\n\n\nRefer to the \nFAQ\n for issues installing gems\n\n\n\n\n\n\nInstall one of two database options\n\n\n\n\nSQLite\n should \nonly\n be used in development\n\n\nMySQL\n can be used in development or production\n\n\n\n\n\n\n\n\nConfigure your database:\n\n\n1\ncp config/database.yml.template config/database.yml\n\n\n\n\n\n\nEdit \ndatabase.yml\n with the correct credentials for your chosen database. Refer to the \nFAQ\n for any issues.\n\n\n\n\n\n\nConfigure the Devise Auth System with a unique key (run these commands exactly):\n\n\n1\n2\ncp config/nitializers/devise.rb.template config/initializers/devise.rb\nsed -i \ns/\nYOUR-SECRET-KEY\n/`bundle exec rake secret`/g\n initializers/devise.rb\n\n\n\n\n\n\nFill in \nYOUR_WEBSITE\n in \nconfig/initializers/devise.rb\n file. To skip this step for now, fill with \nfoo.bar\n.\n\n\n\n\n\n\nCreate and initialize the database tables:\n\n\n1\nbundle exec rake db:create\n\n\n\n\n\n\nDo not forget to use bundle exec in front of every rake/rails command.\n\n\n\n\n\n\nPopulate dummy data (development only):\n\n\n1\nbundle exec rake autolab:populate\n\n\n\n\n\n\n\n\n\n\nStart the rails server:\n\n\n1\nbundle exec rails s -p 3000\n\n\n\n\n\n\n\n\n\n\nGo to localhost:3000 and login with \nDeveloper Login\n:\n\n\n1\nEmail: \nadmin@foo.bar\n.\n\n\n\n\n\n\n\n\n\n\nInstall \nTango\n, the backend autograding service.\n\n\n\n\n\n\nFAQ\n\n\nThis is a general list of questions that we get often. If you find a solution to an issue not mentioned here,\nplease contact us at \n\n\nUbuntu Script Bugs\n\n\nIf you get the following error\n\n\n1\n2\nFailed to fetch http://dl.google.com/linux/chrome/deb/dists/stable/Release  \nUnable to find expected entry \nmain/binary-i386/Packages\n in Release file \n(\nWrong sources.list entry or malformed file\n)\n\n\n\n\n\n\n\nthen follow the solution in \nthis post\n. \n\n\nWhere do I find the MySQL username and password?\n\n\nIf this is your first time logging into MySQL, your username is 'root'. You may also need to set the root password:\n\n\nStart the server:\n\n\n1\nsudo /usr/local/mysql/support-files/mysql.server start\n\n\n\n\n\n\nSet the password:\n\n\n1\nmysqladmin -u root password \n[New_Password]\n\n\n\n\n\n\n\nIf you lost your root password, refer to the \nMySQL wiki\n\n\nBundle Install Errors\n\n\nThis happens as gems get updated. These fixes are gem-specific, but two common ones are\n\n\neventmachine\n\n\n1\nbundle config build.eventmachine --with-cppflags\n=\n-I/usr/local/opt/openssl/include\n\n\n\n\n\n\nlibv8\n\n\n1\nbundle config build.libv8 --with-system-v8\n\n\n\n\n\n\nRun \nbundle install\n again\n\n\nIf this still does not work, try exploring \nthis StackOverflow link\n\n\nCan't connect to local MySQL server through socket\n\n\nMake sure you've started the MySQL server and double-check the socket in \nconfig/database.yml\n\n\nThe default socket location is \n/tmp/mysql.sock\n.", 
            "title": "Autolab"
        }, 
        {
            "location": "/#welcome-to-the-autolab-docs", 
            "text": "Autolab is a course management and homework autograding platform that enables instructors to offer programming labs to their students. It includes gradebooks, rosters, handins/handouts, lab writeups, code annotation, manual grading, late penalties, grace days, cheat checking, meetings, partners, and bulk emails.", 
            "title": "Welcome to the Autolab Docs"
        }, 
        {
            "location": "/#getting-started", 
            "text": "For information on how to use Autolab go to the  instructors page . To learn how to write an autograded lab go to the  lab authors page  Autolab consists of two services, the Ruby on Rails frontend and  Tango , the Python grading server. In order, to use all features\nof Autolab, we highly recommend installing both services.  Currently, we have support for installation on  Ubuntu 14.04+  and  Mac OSX", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#ubuntu-1404", 
            "text": "The following command runs a script that installs Autolab and all it's dependancies. You will be prompted for the  sudo  password and other confirmations. You can see the details of the script  here  1 AUTOLAB_SCRIPT = ` mktemp `     \\c url -sSL https://raw.githubusercontent.com/autolab/Autolab/master/bin/setup.sh    $AUTOLAB_SCRIPT     \\b ash  $AUTOLAB_SCRIPT", 
            "title": "Ubuntu 14.04+"
        }, 
        {
            "location": "/#mac-osx", 
            "text": "Follow the step-by-step instructions below:    Install  rbenv  (use the Basic GitHub Checkout method)    Install  ruby-build  as an rbenv plugin:  1 git clone https://github.com/sstephenson/ruby-build.git ~/.rbenv/plugins/ruby-build   Restart your shell at this point in order to start using your newly installed rbenv    Install the correct version of ruby:  1 rbenv install $(cat .ruby-version)   At this point, confirm that  rbenv  is working (you might need to restart your shell):  1\n2\n3\n4\n5 $ which ruby\n~/.rbenv/shims/ruby\n\n$ which rake\n~/.rbenv/shims/rake     Install  bundler :  1\n2 gem install bundler\nrbenv rehash     Clone the Autolab repo into any desired directory:  1 git clone https://github.com/autolab/Autolab.git     Install the required gems (run the following commands in the cloned Autolab repo):  1\n2 cd bin\nbundle install   Refer to the  FAQ  for issues installing gems    Install one of two database options   SQLite  should  only  be used in development  MySQL  can be used in development or production     Configure your database:  1 cp config/database.yml.template config/database.yml   Edit  database.yml  with the correct credentials for your chosen database. Refer to the  FAQ  for any issues.    Configure the Devise Auth System with a unique key (run these commands exactly):  1\n2 cp config/nitializers/devise.rb.template config/initializers/devise.rb\nsed -i  s/ YOUR-SECRET-KEY /`bundle exec rake secret`/g  initializers/devise.rb   Fill in  YOUR_WEBSITE  in  config/initializers/devise.rb  file. To skip this step for now, fill with  foo.bar .    Create and initialize the database tables:  1 bundle exec rake db:create   Do not forget to use bundle exec in front of every rake/rails command.    Populate dummy data (development only):  1 bundle exec rake autolab:populate     Start the rails server:  1 bundle exec rails s -p 3000     Go to localhost:3000 and login with  Developer Login :  1 Email:  admin@foo.bar .     Install  Tango , the backend autograding service.", 
            "title": "Mac OSX"
        }, 
        {
            "location": "/#faq", 
            "text": "This is a general list of questions that we get often. If you find a solution to an issue not mentioned here,\nplease contact us at", 
            "title": "FAQ"
        }, 
        {
            "location": "/#ubuntu-script-bugs", 
            "text": "If you get the following error  1\n2 Failed to fetch http://dl.google.com/linux/chrome/deb/dists/stable/Release  \nUnable to find expected entry  main/binary-i386/Packages  in Release file  ( Wrong sources.list entry or malformed file )    then follow the solution in  this post .", 
            "title": "Ubuntu Script Bugs"
        }, 
        {
            "location": "/#where-do-i-find-the-mysql-username-and-password", 
            "text": "If this is your first time logging into MySQL, your username is 'root'. You may also need to set the root password:  Start the server:  1 sudo /usr/local/mysql/support-files/mysql.server start   Set the password:  1 mysqladmin -u root password  [New_Password]    If you lost your root password, refer to the  MySQL wiki", 
            "title": "Where do I find the MySQL username and password?"
        }, 
        {
            "location": "/#bundle-install-errors", 
            "text": "This happens as gems get updated. These fixes are gem-specific, but two common ones are  eventmachine  1 bundle config build.eventmachine --with-cppflags = -I/usr/local/opt/openssl/include   libv8  1 bundle config build.libv8 --with-system-v8   Run  bundle install  again  If this still does not work, try exploring  this StackOverflow link", 
            "title": "Bundle Install Errors"
        }, 
        {
            "location": "/#cant-connect-to-local-mysql-server-through-socket", 
            "text": "Make sure you've started the MySQL server and double-check the socket in  config/database.yml  The default socket location is  /tmp/mysql.sock .", 
            "title": "Can't connect to local MySQL server through socket"
        }, 
        {
            "location": "/tango/", 
            "text": "Tango\n\n\nTango is a standalone RESTful Web service that runs jobs in virtual machines or containers. It was developed as a distributed grading system for \nAutolab\n and has been extensively used for autograding programming assignments.\n\n\nGetting Started\n\n\nA brief overview of the Tango respository:\n\n\n\n\ntango.py\n - Main tango server\n\n\njobQueue.py\n - Manages the job queue\n\n\njobManager.py\n - Assigns jobs to free VMs\n\n\nworker.py\n - Shepherds a job through its execution\n\n\npreallocator.py\n - Manages pools of VMs\n\n\nvmms/\n - VMMS library implementations\n\n\nrestful-tango/\n - HTTP server layer on the main Tango\n\n\n\n\nTango runs jobs in VMs using a high level Virtual Memory Management System (VMMS) API. Tango currently has support for running jobs in Docker containers (\nrecommended\n), \nTashi VMs\n, or Amazon EC2.\n\n\nFor more information about the different Tango components, go to the following pages:", 
            "title": "Tango"
        }, 
        {
            "location": "/tango/#tango", 
            "text": "Tango is a standalone RESTful Web service that runs jobs in virtual machines or containers. It was developed as a distributed grading system for  Autolab  and has been extensively used for autograding programming assignments.", 
            "title": "Tango"
        }, 
        {
            "location": "/tango/#getting-started", 
            "text": "A brief overview of the Tango respository:   tango.py  - Main tango server  jobQueue.py  - Manages the job queue  jobManager.py  - Assigns jobs to free VMs  worker.py  - Shepherds a job through its execution  preallocator.py  - Manages pools of VMs  vmms/  - VMMS library implementations  restful-tango/  - HTTP server layer on the main Tango   Tango runs jobs in VMs using a high level Virtual Memory Management System (VMMS) API. Tango currently has support for running jobs in Docker containers ( recommended ),  Tashi VMs , or Amazon EC2.  For more information about the different Tango components, go to the following pages:", 
            "title": "Getting Started"
        }, 
        {
            "location": "/instructors/", 
            "text": "Instructor's Guide\n\n\nThis document provides instructors with a brief overview of the basic ideas and capabilities of the Autolab system. It's meant to be read from beginning to end the first time. \n\n\nUsers\n\n\nUsers\n are either \ninstructors\n, \ncourse assistants\n, or \nstudents\n. Instructors have full permissions. Course assistants are only allowed to enter grades. Students see only their own work. Each user is uniquely identified by their email address. You can change the permissions for a particular user at any time. Note that some instructors opt to give some or all of their TAs instructor status.\n\n\nRoster\n\n\nThe \nroster\n holds the list of users. You can add and remove users one at a time, or in bulk by uploading a CSV file in the general Autolab format:\n\n\nSemester,email,last_name,first_name,school,major,year,grading_policy,courseNumber,courseLecture,section\n\n\nor in the format that is exported by the CMU S3 service:\n\n\n\"Semester\",\"Course\",\"Section\",\"Lecture\",\"Mini\",\"Last Name\",\"First Name\",\"MI\",\"AndrewID\",\"Email\",\"College\",\"Department\",...\n\n\n\n\n\nAttention CMU Instructors:\n\n\nS3 lists each student twice: once in a lecture roster, which lists the lecture number (e.g., 1, 2,...) in the section field, and once in a section roster, which lists the section letter (e.g., A, B,...) in the section field. Be careful not to import the lecture roster. Instead, export and upload each section individually. Or you can export everything from S3 with a single action, edit out the roster entries for the lecture(s), and then upload a single file to Autolab with all of the sections.\n\n\n\n\nFor the bulk upload, you can choose to either: \n\n\n\n \nadd\n any new students in the roster file to the Autolab roster, or to \n\n\n \nupdate\n the Autolab roster by marking students missing from roster files as \ndropped\n.\n \n\n\n\nInstructors and course assistants are never marked as dropped. User accounts are never deleted. Students marked as dropped can still see their work, but cannot submit new work and do not appear on the instructor gradebook. Instructors can change the dropped status of a student at any time. \n\n\nOnce a student is added to the roster for a course, then that course becomes visible to the student when they visit the Autolab site. A student can be enrolled in an arbitrary number of Autolab courses.\n\n\nLabs (Assessments)\n\n\nA \nlab\n (or \nassessment\n) \nis broadly defined as a submission set; it is anything that\nyour students make submissions (handins) for. This could be a programming assignment, a\ntyped homework, or even an in-class exam. You can create labs from scratch, or reuse them from previous semesters.\nSee the companion [[Guide for Lab Authors]] for info on writing and installing labs. \n\n\nAssessment Categories\n\n\nYou can tag each assessment with an arbitrary user-defined \ncategory\n, e.g., \"Lab\", \"Exam\", \"Homework\".\n\n\nAutograders and Scoreboards\n\n\nLabs can be \nautograded\n or not, at your disrcretion. When a student submits to an autograded lab, Autolab runs an instructor-supplied \nautograder\n program that assigns scores to one or more problems associated with the lab. Autograded labs can have an optional \nscoreboard\n that shows (anonymized) results in real-time. See the companion [[Guide for Lab Authors]] for details on writing autograded labs with scoreboards.\n\n\nImportant Dates\n\n\nA lab has a \nstart date\n, \ndue date\n, \nend date\n and \ngrading deadline\n. The link to a lab becomes visible to students after the start date (it's always visible to instructors). Students can submit until the due date without penalty or consuming grace days. Submission is turned off after the end date. Grades are included in the gradebook's category and course averages only after the grading deadline.\n\n\nHandins\n\n\nOnce an assessment is live (past the start date), students can begin submitting handins, where each handin is a single file, which can be either a text file or an archive file (e.g., \nmm.c\n, \nhandin.tar\n).\n\n\nPenalties and Extensions\n\n\nYou can set penalties for late handins, set hard limits on the number of handins, or set soft limits that penalize excessive handins on a sliding scale. You can also give a student an \nextension\n that\nextends the due dates and end dates for that student.\n\n\nGrace Days\n\n\nAutolab provides support for a late handin policy based on \ngrace days\n. Each\nstudent has a semester-long budget of grace days that are automatically applied if they handin after the due date.\nEach late day consumes one of the budgeted grace days. The Autolab system keeps track of the number of grace days that have been used by each student to date. If students run out of grace days and handin late, then there\nis a fixed late penalty (possibly zero) that can be set by the instructor.\n\n\nProblems\n\n\nEach lab contains at least one \nproblem\n, defined by the instructor, with some point value. Each problem has a name (e.g., \"Prob1\", \"Style\") that is unique for the lab (although different labs can have the same problem names).\n\n\nSubmissions\n\n\nOnce an assessment is live (past the start date), students can begin making submissions (handins),  where each submission is a single file.\n\n\nGrades\n\n\nGrades\n come in a number of different forms:\n\n\n\nProblem scores:\n These are scalar values (possibly negative) assigned per problem per submission, either manually by a human grader after the end date, or automatically by an autograder after each submission. Problem scores can also be uploaded (imported) in bulk from a CSV file. \n\n\nAssessment raw score:\n By default, the raw score is the sum of the individual problem scores, before \nany penalties are applied. You can override the default raw score calculation. See below.\n\n\n\nAssessment total score:\n The total score is the raw score, plus any late penalties, plus any instructor \ntweaks\n.\n\n\n\nCategory averages:\n This is the average for a particular student over all\nassessments in a specific instructor-defined category such as \"Labs, or \"Exams\".\nBy default the category average is the arithmetic mean of all assessment total scores, but it can be overwridden.\nSee below.\n\n\n\nCourse Average:\n By default, the course average is average of all category averages, but can be overidden.\nSee below.\n\n\n\n\n\n\nSubmissions can be\nclassified as one of three types: \"Normal\", \"No Grade\" or \"Excused\". A \"No\nGrade\" submission will show up in the gradebook as NG and a zero will be used\nwhen calculating averages. An \"Excused\" submission will show up in the\ngradebook as EXC and will not be used when calculating averages.\n\n\nOverriding Raw Score Calculations\n\n\nAutolab computes raw scores for a lab with a Ruby function called \nraw_score\n. The default is the sum of the individual problem scores. But you can change this by providing your own \nraw_score\n function in \nlabname\n.rb\n file. For example, to override the raw_score calculation for a lab called \nmalloclab\n, you might add the following \nraw_score\n function to \nmalloclab/malloclab.rb\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n  \n# In malloclab/malloclab.rb file\n\n  \ndef\n \nraw_score\n(\nscore\n)\n\n    \nperfindex\n \n=\n \nscore\n[\nAutograded Score\n].\nto_f\n()\n\n    \nheap\n \n=\n \nscore\n[\nHeap Checker\n].\nto_f\n()\n\n    \nstyle\n \n=\n \nscore\n[\nStyle\n].\nto_f\n()\n\n    \ndeduct\n \n=\n \nscore\n[\nCorrectnessDeductions\n].\nto_f\n()\n\n    \nperfpoints\n \n=\n \nperfindex\n\n\n    \n# perfindex below 50 gets autograded score of 0. \n\n    \nif\n \nperfindex\n \n \n50\n.\n0\n \nthen\n\n      \nperfpoints\n \n=\n \n0\n\n    \nelse\n\n      \nperfpoints\n \n=\n \nperfindex\n\n    \nend\n\n\n    \nreturn\n \nperfpoints\n \n+\n \nheap\n \n+\n \nstyle\n \n+\n \ndeduct\n\n  \nend\n\n\n\n\n\n\n\nThis particular lab has four problems called \"Autograded Score\",  \"Heap Checker\", \"Style\", and \"CorrectnessDeductions\". An \"Autograded Score\" less than 50 is set to zero when the raw score is calculated. \n\n\nNote: To make this change live, you must select the \"Reload config file\" option on the \nmalloclab\n page.\n\n\nOverriding Category and Course Averages\n\n\nThe average for a category \nfoo\n is calculated by a default Ruby function called \nfooAverage\n, which you can override in the \ncourse.rb\n file. For example, in our course, we prefer to report the \"average\" as the total number of normalized points (out of 100) that the student has accrued so far. This helps them understand where they stand in the class, e.g., \"Going into the final exam (worth 30 normalized points), I have 60 normalized points, so the only way to get an A is to get 100% on the final.\" Here's the Ruby function for category \"Lab\":\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# In course.rb file\n\n\ndef\n \nLabAverage\n(\nuser\n)\n\n    \npts\n \n=\n \n(\nuser\n[\ndatalab\n].\nto_f\n()\n \n/\n \n63\n.\n0\n)\n \n*\n \n6\n.\n0\n \n+\n\n      \n(\nuser\n[\nbomblab\n].\nto_f\n()\n \n/\n \n70\n.\n0\n)\n \n*\n \n5\n.\n0\n \n+\n \n      \n(\nuser\n[\nattacklab\n].\nto_f\n()\n \n/\n \n100\n.\n0\n)\n \n*\n \n4\n.\n0\n \n+\n\n      \n(\nuser\n[\ncachelab\n].\nto_f\n()\n \n/\n \n60\n.\n0\n)\n \n*\n \n7\n.\n0\n \n+\n\n      \n(\nuser\n[\ntshlab\n].\nto_f\n()\n \n/\n \n110\n.\n0\n)\n \n*\n \n8\n.\n0\n \n+\n\n      \n(\nuser\n[\nmalloclab\n].\nto_f\n()\n \n/\n \n120\n.\n0\n)\n \n*\n \n12\n.\n0\n \n+\n\n      \n(\nuser\n[\nproxylab\n].\nto_f\n()\n \n/\n \n100\n.\n0\n)\n \n*\n \n8\n.\n0\n \n    \nreturn\n \npts\n.\nto_f\n()\n.\nround\n(\n2\n)\n\n\nend\n\n\n\n\n\n\n\nIn this case, labs are worth a total of 50/100 normalized points. The assessment called \ndatalab\n is graded out of a total of 63 points and is worth 6/50 normalized points.\n\n\nHere is the Ruby function for category \"Exam\":\n\n\n1\n2\n3\n4\n5\n6\n# In course.rb file\n\n\ndef\n \nExamAverage\n(\nuser\n)\n \n    \npts\n \n=\n \n((\nuser\n[\nmidterm\n].\nto_f\n()\n/\n60\n.\n0\n)\n \n*\n \n20\n.\n0\n)\n \n+\n\n          \n((\nuser\n[\nfinal\n].\nto_f\n()\n/\n80\n.\n0\n)\n*\n \n30\n.\n0\n)\n \n    \nreturn\n \npts\n.\nto_f\n()\n.\nround\n(\n2\n)\n \n\nend\n\n\n\n\n\n\n\nIn this case, exams are worth 50/100 normalized points. The assessment called \nmidterm\n is graded out of total of 60 points and is worth 20/50 normalized points.\n\n\nThe course average is computed by a default Ruby function called \ncourseAverage\n, which can be overridden by the \ncourse.rb\n file in the course directory. Here is the function for our running example:\n\n\n1\n2\n3\n4\n5\n# In course.rb file\n\n\ndef\n \ncourseAverage\n(\nuser\n)\n\n    \npts\n \n=\n \nuser\n[\ncatLab\n].\nto_f\n()\n \n+\n \nuser\n[\ncatExam\n].\nto_f\n()\n\n    \nreturn\n \npts\n.\nto_f\n()\n.\nround\n(\n2\n)\n\n\nend\n\n\n\n\n\n\n\nIn this course, the course average is the sum of the category averages for \"Lab\" and \"Exam\".\n\n\nNote: To make these changes live, you must select \"Reload course config file\" on the \"Manage course\" page.\n\n\nHandin History\n\n\nFor each lab, students can view all of their submissions, including any source code, and the problem scores, penalties, and total scores associated with those submissions, via the \nhandin history\n page.\n\n\nGradesheet\n\n\nThe \ngradesheet\n (not to be confused with the \ngradebook\n) is the workhorse grading tool. Each assessment has a separate gradesheet with the following features:\n\n\n\nProvides an interface for manually entering problem scores (and problem feedback) for the most recent submmission from each student. \n\n\nProvides an interface for viewing and annotating the submitted code.\n\n\nDisplays the problem scores for the most recent submission for each student, summarizes any late penalties, and computes the total score.\n\n\nProvides a link to each student's handin history.\n\n\n\n\nGradebook\n\n\nThe \ngradebook\n comes in two forms. The \nstudent gradebook\n displays the \ngrades for a particular student, including total scores for each assessment, category averages, and the course average. The \ninstructor gradebook\n is a table that displays the grades for the most recent submission of each student, including assessment total scores, category averages and course average. \n\n\nFor the gradebook calculations, submissions are \nclassified as one of three types: \"Normal\", \"No Grade\" or \"Excused\". A \"No\nGrade\" submission will show up in the gradebook as NG and a zero will be used\nwhen calculating averages. An \"Excused\" submission will show up in the\ngradebook as EXC and will not be used when calculating averages.\n\n\nReleasing Grades\n\n\nManually assigned grades are by default not released, and therefore not visible to\nstudents. You can release grades on an individual basis while grading, or\nrelease all available grades in bulk by using the \"Release all grades\" option. You can also reverse this\nprocess using the \"Withdraw all grades\" option. (The word \"withdraw\" is perhaps unfortunate. No grades are ever deleted. They are simply withdrawn from the student's view.)", 
            "title": "Guide for Instructors"
        }, 
        {
            "location": "/instructors/#instructors-guide", 
            "text": "This document provides instructors with a brief overview of the basic ideas and capabilities of the Autolab system. It's meant to be read from beginning to end the first time.", 
            "title": "Instructor's Guide"
        }, 
        {
            "location": "/instructors/#users", 
            "text": "Users  are either  instructors ,  course assistants , or  students . Instructors have full permissions. Course assistants are only allowed to enter grades. Students see only their own work. Each user is uniquely identified by their email address. You can change the permissions for a particular user at any time. Note that some instructors opt to give some or all of their TAs instructor status.", 
            "title": "Users"
        }, 
        {
            "location": "/instructors/#roster", 
            "text": "The  roster  holds the list of users. You can add and remove users one at a time, or in bulk by uploading a CSV file in the general Autolab format: \nSemester,email,last_name,first_name,school,major,year,grading_policy,courseNumber,courseLecture,section \nor in the format that is exported by the CMU S3 service: \n\"Semester\",\"Course\",\"Section\",\"Lecture\",\"Mini\",\"Last Name\",\"First Name\",\"MI\",\"AndrewID\",\"Email\",\"College\",\"Department\",...   Attention CMU Instructors:  S3 lists each student twice: once in a lecture roster, which lists the lecture number (e.g., 1, 2,...) in the section field, and once in a section roster, which lists the section letter (e.g., A, B,...) in the section field. Be careful not to import the lecture roster. Instead, export and upload each section individually. Or you can export everything from S3 with a single action, edit out the roster entries for the lecture(s), and then upload a single file to Autolab with all of the sections.   For the bulk upload, you can choose to either:     add  any new students in the roster file to the Autolab roster, or to     update  the Autolab roster by marking students missing from roster files as  dropped .    Instructors and course assistants are never marked as dropped. User accounts are never deleted. Students marked as dropped can still see their work, but cannot submit new work and do not appear on the instructor gradebook. Instructors can change the dropped status of a student at any time.   Once a student is added to the roster for a course, then that course becomes visible to the student when they visit the Autolab site. A student can be enrolled in an arbitrary number of Autolab courses.", 
            "title": "Roster"
        }, 
        {
            "location": "/instructors/#labs-assessments", 
            "text": "A  lab  (or  assessment ) \nis broadly defined as a submission set; it is anything that\nyour students make submissions (handins) for. This could be a programming assignment, a\ntyped homework, or even an in-class exam. You can create labs from scratch, or reuse them from previous semesters.\nSee the companion [[Guide for Lab Authors]] for info on writing and installing labs.", 
            "title": "Labs (Assessments)"
        }, 
        {
            "location": "/instructors/#assessment-categories", 
            "text": "You can tag each assessment with an arbitrary user-defined  category , e.g., \"Lab\", \"Exam\", \"Homework\".", 
            "title": "Assessment Categories"
        }, 
        {
            "location": "/instructors/#autograders-and-scoreboards", 
            "text": "Labs can be  autograded  or not, at your disrcretion. When a student submits to an autograded lab, Autolab runs an instructor-supplied  autograder  program that assigns scores to one or more problems associated with the lab. Autograded labs can have an optional  scoreboard  that shows (anonymized) results in real-time. See the companion [[Guide for Lab Authors]] for details on writing autograded labs with scoreboards.", 
            "title": "Autograders and Scoreboards"
        }, 
        {
            "location": "/instructors/#important-dates", 
            "text": "A lab has a  start date ,  due date ,  end date  and  grading deadline . The link to a lab becomes visible to students after the start date (it's always visible to instructors). Students can submit until the due date without penalty or consuming grace days. Submission is turned off after the end date. Grades are included in the gradebook's category and course averages only after the grading deadline.", 
            "title": "Important Dates"
        }, 
        {
            "location": "/instructors/#handins", 
            "text": "Once an assessment is live (past the start date), students can begin submitting handins, where each handin is a single file, which can be either a text file or an archive file (e.g.,  mm.c ,  handin.tar ).", 
            "title": "Handins"
        }, 
        {
            "location": "/instructors/#penalties-and-extensions", 
            "text": "You can set penalties for late handins, set hard limits on the number of handins, or set soft limits that penalize excessive handins on a sliding scale. You can also give a student an  extension  that\nextends the due dates and end dates for that student.", 
            "title": "Penalties and Extensions"
        }, 
        {
            "location": "/instructors/#grace-days", 
            "text": "Autolab provides support for a late handin policy based on  grace days . Each\nstudent has a semester-long budget of grace days that are automatically applied if they handin after the due date.\nEach late day consumes one of the budgeted grace days. The Autolab system keeps track of the number of grace days that have been used by each student to date. If students run out of grace days and handin late, then there\nis a fixed late penalty (possibly zero) that can be set by the instructor.", 
            "title": "Grace Days"
        }, 
        {
            "location": "/instructors/#problems", 
            "text": "Each lab contains at least one  problem , defined by the instructor, with some point value. Each problem has a name (e.g., \"Prob1\", \"Style\") that is unique for the lab (although different labs can have the same problem names).", 
            "title": "Problems"
        }, 
        {
            "location": "/instructors/#submissions", 
            "text": "Once an assessment is live (past the start date), students can begin making submissions (handins),  where each submission is a single file.", 
            "title": "Submissions"
        }, 
        {
            "location": "/instructors/#grades", 
            "text": "Grades  come in a number of different forms:  Problem scores:  These are scalar values (possibly negative) assigned per problem per submission, either manually by a human grader after the end date, or automatically by an autograder after each submission. Problem scores can also be uploaded (imported) in bulk from a CSV file.   Assessment raw score:  By default, the raw score is the sum of the individual problem scores, before \nany penalties are applied. You can override the default raw score calculation. See below.  Assessment total score:  The total score is the raw score, plus any late penalties, plus any instructor  tweaks .  Category averages:  This is the average for a particular student over all\nassessments in a specific instructor-defined category such as \"Labs, or \"Exams\".\nBy default the category average is the arithmetic mean of all assessment total scores, but it can be overwridden.\nSee below.  Course Average:  By default, the course average is average of all category averages, but can be overidden.\nSee below.   Submissions can be\nclassified as one of three types: \"Normal\", \"No Grade\" or \"Excused\". A \"No\nGrade\" submission will show up in the gradebook as NG and a zero will be used\nwhen calculating averages. An \"Excused\" submission will show up in the\ngradebook as EXC and will not be used when calculating averages.", 
            "title": "Grades"
        }, 
        {
            "location": "/instructors/#overriding-raw-score-calculations", 
            "text": "Autolab computes raw scores for a lab with a Ruby function called  raw_score . The default is the sum of the individual problem scores. But you can change this by providing your own  raw_score  function in  labname .rb  file. For example, to override the raw_score calculation for a lab called  malloclab , you might add the following  raw_score  function to  malloclab/malloclab.rb :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17    # In malloclab/malloclab.rb file \n   def   raw_score ( score ) \n     perfindex   =   score [ Autograded Score ]. to_f () \n     heap   =   score [ Heap Checker ]. to_f () \n     style   =   score [ Style ]. to_f () \n     deduct   =   score [ CorrectnessDeductions ]. to_f () \n     perfpoints   =   perfindex \n\n     # perfindex below 50 gets autograded score of 0.  \n     if   perfindex     50 . 0   then \n       perfpoints   =   0 \n     else \n       perfpoints   =   perfindex \n     end \n\n     return   perfpoints   +   heap   +   style   +   deduct \n   end    This particular lab has four problems called \"Autograded Score\",  \"Heap Checker\", \"Style\", and \"CorrectnessDeductions\". An \"Autograded Score\" less than 50 is set to zero when the raw score is calculated.   Note: To make this change live, you must select the \"Reload config file\" option on the  malloclab  page.", 
            "title": "Overriding Raw Score Calculations"
        }, 
        {
            "location": "/instructors/#overriding-category-and-course-averages", 
            "text": "The average for a category  foo  is calculated by a default Ruby function called  fooAverage , which you can override in the  course.rb  file. For example, in our course, we prefer to report the \"average\" as the total number of normalized points (out of 100) that the student has accrued so far. This helps them understand where they stand in the class, e.g., \"Going into the final exam (worth 30 normalized points), I have 60 normalized points, so the only way to get an A is to get 100% on the final.\" Here's the Ruby function for category \"Lab\":   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 # In course.rb file  def   LabAverage ( user ) \n     pts   =   ( user [ datalab ]. to_f ()   /   63 . 0 )   *   6 . 0   + \n       ( user [ bomblab ]. to_f ()   /   70 . 0 )   *   5 . 0   +  \n       ( user [ attacklab ]. to_f ()   /   100 . 0 )   *   4 . 0   + \n       ( user [ cachelab ]. to_f ()   /   60 . 0 )   *   7 . 0   + \n       ( user [ tshlab ]. to_f ()   /   110 . 0 )   *   8 . 0   + \n       ( user [ malloclab ]. to_f ()   /   120 . 0 )   *   12 . 0   + \n       ( user [ proxylab ]. to_f ()   /   100 . 0 )   *   8 . 0  \n     return   pts . to_f () . round ( 2 )  end    In this case, labs are worth a total of 50/100 normalized points. The assessment called  datalab  is graded out of a total of 63 points and is worth 6/50 normalized points.  Here is the Ruby function for category \"Exam\":  1\n2\n3\n4\n5\n6 # In course.rb file  def   ExamAverage ( user )  \n     pts   =   (( user [ midterm ]. to_f () / 60 . 0 )   *   20 . 0 )   + \n           (( user [ final ]. to_f () / 80 . 0 ) *   30 . 0 )  \n     return   pts . to_f () . round ( 2 )   end    In this case, exams are worth 50/100 normalized points. The assessment called  midterm  is graded out of total of 60 points and is worth 20/50 normalized points.  The course average is computed by a default Ruby function called  courseAverage , which can be overridden by the  course.rb  file in the course directory. Here is the function for our running example:  1\n2\n3\n4\n5 # In course.rb file  def   courseAverage ( user ) \n     pts   =   user [ catLab ]. to_f ()   +   user [ catExam ]. to_f () \n     return   pts . to_f () . round ( 2 )  end    In this course, the course average is the sum of the category averages for \"Lab\" and \"Exam\".  Note: To make these changes live, you must select \"Reload course config file\" on the \"Manage course\" page.", 
            "title": "Overriding Category and Course Averages"
        }, 
        {
            "location": "/instructors/#handin-history", 
            "text": "For each lab, students can view all of their submissions, including any source code, and the problem scores, penalties, and total scores associated with those submissions, via the  handin history  page.", 
            "title": "Handin History"
        }, 
        {
            "location": "/instructors/#gradesheet", 
            "text": "The  gradesheet  (not to be confused with the  gradebook ) is the workhorse grading tool. Each assessment has a separate gradesheet with the following features:  Provides an interface for manually entering problem scores (and problem feedback) for the most recent submmission from each student.   Provides an interface for viewing and annotating the submitted code.  Displays the problem scores for the most recent submission for each student, summarizes any late penalties, and computes the total score.  Provides a link to each student's handin history.", 
            "title": "Gradesheet"
        }, 
        {
            "location": "/instructors/#gradebook", 
            "text": "The  gradebook  comes in two forms. The  student gradebook  displays the \ngrades for a particular student, including total scores for each assessment, category averages, and the course average. The  instructor gradebook  is a table that displays the grades for the most recent submission of each student, including assessment total scores, category averages and course average.   For the gradebook calculations, submissions are \nclassified as one of three types: \"Normal\", \"No Grade\" or \"Excused\". A \"No\nGrade\" submission will show up in the gradebook as NG and a zero will be used\nwhen calculating averages. An \"Excused\" submission will show up in the\ngradebook as EXC and will not be used when calculating averages.", 
            "title": "Gradebook"
        }, 
        {
            "location": "/instructors/#releasing-grades", 
            "text": "Manually assigned grades are by default not released, and therefore not visible to\nstudents. You can release grades on an individual basis while grading, or\nrelease all available grades in bulk by using the \"Release all grades\" option. You can also reverse this\nprocess using the \"Withdraw all grades\" option. (The word \"withdraw\" is perhaps unfortunate. No grades are ever deleted. They are simply withdrawn from the student's view.)", 
            "title": "Releasing Grades"
        }, 
        {
            "location": "/lab/", 
            "text": "This guide explains how to create autograded programming assignments (labs) for the Autolab system. \n\n\nWriting Autograders\n\n\nAn \nautograder\n is a program that takes a student's work as input, and generates some quantitative evaluation of that work as output. The student's work consists of one or more source files written in an arbitrary programming language. \nThe autograder processes these files and generates arbitrary text lines on stdout. The last text line on stdout must be a JSON string, called an \nautoresult\n, that assigns an autograded score to one or more problems, and optionally, generates the scoreboard entries for this submission.\n\n\nThe JSON autoresult is a \"scores\" hash that assigns a numerical score to one or more problems, and an optional \"scoreboard\" array that provides the scoreboard entries for this submission. For example, \n\n\n1\n{\nscores\n: {\nProb1\n: 10, \nProb2\n: 5}}\n\n\n\n\n\n\nassigns 10 points to \"Prob1\" and 5 points to \"Prob2\" for this submission. The names of the problems must exactly match the names of the problems for this lab on the Autolab web site. Not all problems need to be autograded. For example, there might be a problem for this assessment called \"Style\" that you grade manually after the due date. \n\n\nIf you used the Autolab web site to configure a scoreboard for this lab with three columns called \"Prob1\", \"Prob2\", and \"Total\", then the autoresult might be: \n\n\n1\n{\nscores\n: {\nProb1\n: 10, \nProb2\n: 5}, \nscoreboard\n: [10, 5, 15]}\n\n\n\n\n\n\nBy convention, an autograder accepts an optional \n-A\n command line argument that tells it to emit the JSON autoresult. So if you run the autograder outside of the context of Autolab, you can suppress the autoresult line by calling the autograder without the \n-A\n argument.\n\n\nOne of the nice properties of Autolab autograders is that they can be written and tested offline, without requiring any interaction with Autolab. Writing autograders is not easy, but the fact that they can be developed offline allows you to develop and test them in your own familiar computing environment. \n\n\nInstalling Autograded Labs\n\n\nAfter you've written and tested the autograder, you then use the Autolab web site to create the autograded lab. Autolab supports creating new labs from scratch, or reusing labs from previous semesters. We'll describe each of these in turn.\n\n\nCreating an Autograded Lab from Scratch\n\n\nStep 1: Create the new lab.\n\n\nCreate a new lab by clicking the \"Install Assessment\" button and choosing \"Option 1: Create a New Assessment from Scratch.\" For course \ncourse\n and lab \nlab\n,  this will create a \nlab directory\n in the Autolab file hierarchy called \ncourses/\ncourse\n/\nlab\n. This initial directory contains a couple of config files and a directory called \nlab\n/handin\n that will contain all of the student handin files. In general, you should never modify any of these. \n\n\n\n\nAttention CMU Lab Authors\n\n\nAt CMU, the lab directory is called \n/afs/cs/academic/class/\ncourse\n/autolab/\nlab\n. For example: \n/afs/cs/academic/class/15213-f16/autolab/foo\n is the lab directory for the lab named \nfoo\n for the Fall 2016 instance of 15-213. All lab-related files must go in this \nautolab\n directory to avoid permissions issues.\n\n\n\n\nStep 2: Configure the lab for autograding.\n\n\nUsing the \"Edit Assessment\" page, turn on autograding for this lab by selecting \"Add Autograder.\" You will be asked for the name of the image to be used for autograding this lab. The default image distributed with Autolab is an Ubuntu image called \nautograding_image\n. If your class needs different software, then you or your facilities staff will need to update the default image or create a new one. \n\n\n\n\nAttention CMU Lab Authors\n\n\nThe default autograding image at CMU is called \nrhel.img\n and is a copy of the software on the CMU Andrew machines (\nlinux.andrew.cmu.edu\n). If you need custom software installed, please send mail to autolab-help@andrew.cmu.edu.\n\n\n\n\nIf you want a scoreboard, you should select \"Add Scoreboard,\" which will allow you to specify the number of columns and their names. The \"Add Scoreboard\" page contains a tutorial on how to do this. \n\n\nYou'll also need to define the names and point values for all the problems in this lab, including the autograded ones. \n\n\nEach student submission is a single file, either a text source file or an archive file containing multiple files and directories. You'll need to specify the \nbase name\n for the student submission files (e.g., \nmm.c\n, \nhandin.tar\n).\n\n\nStep 3: Add the required autograding files.\n\n\nFor an autograded lab, Autolab expects the following two \nautograding files\n in the lab directory: \n\n\n\n\nautograde-Makefile\n: runs the autograder on a student submission.\n\n\nautograde.tar\n: contains all of the files (except for the student handin file) that are needed for autograding. \n\n\n\n\nEach time a student submits their work or an instructor requests a regrade, Autolab \n\n\n\n\ncopies the student handin file, along with the two autograding files, to an empty directory on an \nautograding instance\n, \n\n\nrenames the student handin file to \nbase name\n (e.g., hello.c, handin.tar), \n\n\nrenames \nautograde-Makefile\n to \nMakefile\n, \n\n\nexecutes the command \nmake\n on the autograding instance, and finally \n\n\ncaptures the stdout generated by the autograder, and parses the resulting JSON autoresult to determine the autograded scores. \n\n\n\n\nImporting an Autograded Lab from a Previous Semester\n\n\nIf you've created a lab for a course in a previous semester and have access to the lab directory (as we do at CMU via AFS), you can import the lab into your current course by \n\n\n\n\ncopying the lab directory from the previous course to the current course, \n\n\ncleaning out the \nhandin\n directory, then \n\n\nvisiting the \"Install Assessment\" page and selecting \"Option 2: Import an existing assessment from the file system.\" Autolab will give you a list of all of the directories that appear to be uninstalled labs, from which you can select your particular lab. \n\n\n\n\nIf you don't have access to the lab directory, another option is to import a lab from a tarball that was created by running \"Export assessment\" in an instance of a lab from a previous semester. Visit the \"Install Assessment\" page and select \"Option 3: Import an existing assessment from tarball.\" This will upload the tarball, create a new lab directory by expanding the tarball, and then import the directory.\n\n\nExample: Hello Lab\n\n\nIn this section we'll look at the simplest possible autograded lab we could imagine, called, appropriately enough, the\n\nHello Lab\n \n(with \ntarball\n), which is stored in a lab directory called \nhello\n in the Autolab github repo. While it's trivial, it illustrates all of the aspects of developing an autograded lab, and provides a simple example that you can use for sanity testing on your Autolab installation.\n\n\nIn this lab, students are asked to write a version of the K\nR \"hello, world\" program, called \nhello.c\n. The autograder simply checks that the submitted \nhello.c\n program compiles and runs with an exit status of zero. If so, the submission gets 100 points. Otherwise it gets 0 points. \n\n\nDirectory Structure\n\n\nAutolab expects to find the \nautograde-Makefile\nand \nautograde.tar\n files in the \nhello\n lab directory, but otherwise places no constraints on the contents and organization of this directory. However, based on our experience, we strongly recommend a directory structure with the following form:\n\n\nhello/README\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n# Basic files created by the lab author\nMakefile                Builds the lab from src/\nREADME                  \nautograde-Makefile      Makefile that runs the autograder \nsrc/                    Contains all src files and solutions         \ntest-autograder/        For testing autograder offline\nwriteup/                Lab writeup that students view from Autolab    \n\n# Files created by running make\nhello-handout/          The directory that is handed out to students, created\n                        using files from src/. \nhello-handout.tar       Archive of hello-handout directory\nautograde.tar           File that is copied to the autograding instance \n                        (along with autograde-Makefile and student handin file)\n\n# Files created and managed by Autolab\nhandin/    All students handin files\nhello.rb   Config file\nhello.yml  Database properties that persist from semester to semester\nlog.txt    Log of autograded submissions\n\n\n\n\n\n\nThe key idea with this directory structure is to place \nall\n code for the lab in the \nsrc\n directory, including the autograding code and any starter code handed out to students in the handout directory (\nhello-handout.tar\n in this example). Keeping all hard state in the \nsrc\n directory helps limit inconsistencies. \n\n\nThe main makefile creates \nhello-handout\n by copying files from \nsrc\n, and then tars it up:\n\n\nhello/Makefile\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n#\n\n\n# Makefile to manage the example Hello Lab\n\n\n#\n\n\n\n# Get the name of the lab directory\n\n\nLAB\n \n=\n \n$(\nnotdir \n$(\nPWD\n))\n\n\n\nall\n:\n \nhandout\n \nhandout\n-\ntarfile\n\n\n\nhandout\n:\n \n\n    # Rebuild the handout directory that students download\n\n    \n(\nrm -rf \n$(\nLAB\n)\n-handout\n;\n mkdir \n$(\nLAB\n)\n-handout\n)\n\n    cp -p src/Makefile-handout \n$(\nLAB\n)\n-handout/Makefile\n    cp -p src/README-handout \n$(\nLAB\n)\n-handout/README\n    cp -p src/hello.c-handout \n$(\nLAB\n)\n-handout/hello.c \n    cp -p src/driver.sh \n$(\nLAB\n)\n-handout\n\n\nhandout-tarfile\n:\n \nhandout\n\n\n    # Build *-handout.tar and autograde.tar\n\n    tar cvf \n$(\nLAB\n)\n-handout.tar \n$(\nLAB\n)\n-handout\n    cp -p \n$(\nLAB\n)\n-handout.tar autograde.tar\n\n\nclean\n:\n\n\n    # Clean the entire lab directory tree.  Note that you can run\n\n\n    # \nmake clean; make\n at any time while the lab is live with no\n\n\n    # adverse effects.\n\n    rm -f *~ *.tar\n    \n(\ncd\n src\n;\n make clean\n)\n\n    \n(\ncd\n test-autograder\n;\n make clean\n)\n\n    rm -rf \n$(\nLAB\n)\n-handout\n    rm -f autograde.tar\n\n#\n\n\n# CAREFULL!!! This will delete all student records in the logfile and\n\n\n# in the handin directory. Don\nt run this once the lab has started.\n\n\n# Use it to clean the directory when you are starting a new version\n\n\n# of the lab from scratch, or when you are debugging the lab prior\n\n\n# to releasing it to the students.\n\n\n#\n\n\ncleanallfiles\n:\n\n\n    # Reset the lab from scratch.\n\n    make clean\n    rm -f log.txt\n    rm -rf handin/*\n\n\n\n\n\n\nFilenames are disambiguated by appending \n-handout\n, which is stripped when they are copied to the handout directory. For example, \nsrc/hello.c\n is the instructor's solution file, and \nsrc/hello.c-handout\n is the starter code that is given to the students in \nhello-handout/hello.c\n. And \nsrc/README\n is the README for the src directory and \nsrc/README-handout\n is the README that is handed out to students in \nhello-handout/README\n.\n\n\nTo build the lab, type \nmake clean; make\n. You can do this as often as you like while the lab is live with no adverse effects. However, be careful to never type \nmake cleanallfiles\n while the lab is live; this should only be done before the lab goes live; never during or after.\n\n\nSource Directory\n\n\nThe \nhello/src/\n directory \ncontains \nall\n of the code files for the Hello Lab, including the files that are handed out to students:\n\n\nhello/src/README\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n# Autograder and solution files\nMakefile                Makefile and ...\nREADME                  ... README for this directory\ndriver.sh*              Autograder\nhello.c                 Solution hello.c file\n\n# Files that are handed out to students\nMakefile-handout        Makefile and ...\nREADME-handout          ... README handed out to students\nhello.c-handout         Blank hello.c file handed out to students\n\n\n\n\n\n\nHandout Directory\n\n\nThe \nhello/hello-handout/\n directory\ncontains the files that the students will use to work on the lab. It contains no hard state, and is populated entirely with files from \nhello/src\n:\n\n\nhello/hello-handout/README\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nFor\n \nthis\n \nlab\n,\n \nyou\n \nshould\n \nwrite\n \na\n \ntiny\n \nC\n \nprogram\n,\n \ncalled\n \nhello.c\n,\n\n\nthat\n \nprints\n \nhello, world\n \nto\n \nstdout\n \nand\n \nthen\n \nindicates\n \nsuccess\n \nby\n\n\nexiting\n \nwith\n \na\n \nstatus\n \nof\n \nzero\n.\n\n\n\nTo\n \ntest\n \nyour\n \nwork\n:\n \n\n$\n \nmake\n \nclean\n;\n \nmake\n;\n \n./\nhello\n\n\n\nTo\n \nrun\n \nthe\n \nsame\n \nautograder\n \nthat\n \nAutolab\n \nwill\n \nuse\n \nwhen\n \nyou\n \nsubmit\n:\n\n\n$\n \n./\ndriver\n.\nsh\n\n\n\nFiles\n:\n\n\nREADME\n          \nThis\n \nfile\n\n\nMakefile\n        \nCompiles\n \nhello\n.\nc\n\n\ndriver\n.\nsh\n       \nAutolab\n \nautograder\n\n\nhello\n.\nc\n         \nEmpty\n \nC\n \nfile\n \nthat\n \nyou\n \nwill\n \nedit\n\n\n\n\n\n\n\nhello/hello-handout/Makefile\n contains the rules that compile the student source code:\n\n\n1\n2\n3\n4\n5\n6\n# Student makefile for the Hello Lab\n\nall: \n    gcc hello.c -o hello\n\nclean:\n    rm -rf *~ hello\n\n\n\n\n\n\nTo compile and run their code, students type:\n\n\n1\n2\n$\n \nmake\n \nclean\n;\n \nmake\n\n\n$\n \n./\nhello\n\n\n\n\n\n\n\nAutograder\n\n\nThe autograder for the Hello Lab is a trivially simple bash script called \ndriver.sh\n that compiles and runs \nhello.c\n and verifies that it returns with an exit status of zero:\n\n\nhello/src/driver.sh\n \n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n#!/bin/bash\n\n\n\n# driver.sh - The simplest autograder we could think of. It checks\n\n\n#   that students can write a C program that compiles, and then\n\n\n#   executes with an exit status of zero.\n\n\n#   Usage: ./driver.sh\n\n\n\n# Compile the code\n\n\necho\n \nCompiling hello.c\n\n\n(\nmake clean\n;\n make\n)\n\n\nstatus\n=\n$?\n\n\nif\n \n[\n \n${\nstatus\n}\n -ne \n0\n \n]\n;\n \nthen\n\n    \necho\n \nFailure: Unable to compile hello.c (return status = \n${\nstatus\n}\n)\n\n    \necho\n \n{\\\nscores\\\n: {\\\nCorrectness\\\n: 0}}\n\n    \nexit\n\n\nfi\n\n\n\n# Run the code\n\n\necho\n \nRunning ./hello\n\n./hello\n\nstatus\n=\n$?\n\n\nif\n \n[\n \n${\nstatus\n}\n -eq \n0\n \n]\n;\n \nthen\n\n    \necho\n \nSuccess: ./hello runs with an exit status of 0\n\n    \necho\n \n{\\\nscores\\\n: {\\\nCorrectness\\\n: 100}}\n\n\nelse\n\n    \necho\n \nFailure: ./hello fails or returns nonzero exit status of \n${\nstatus\n}\n\n    \necho\n \n{\\\nscores\\\n: {\\\nCorrectness\\\n: 0}}\n\n\nfi\n\n\n\nexit\n\n\n\n\n\n\n\nFor example:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n$\n \n./\ndriver\n.\nsh\n\n\n# Compiling hello.c\n\n\n# rm -rf *~ hello\n\n\n# gcc hello.c -o hello\n\n\n# Running ./hello\n\n\n# Hello, world\n\n\n# Success: ./hello runs with an exit status of 0\n\n\n# {\nscores\n: {\nCorrectness\n: 100}}\n\n\n\n\n\n\n\nNotice that the autograder expects the \nhello\n lab on the Autolab front-end to have been defined with a problem called \"Correctness\", with a maximum value of 100 points. If you forget to define the problems listed in the JSON autoresult, scores will still be logged, but they won't be posted to the database. \n\n\nRequired Autograding Files\n\n\nAutolab requires two \nautograding files\n called \nautograde.tar\n, which contains all of the code required by the autograder, and \nautograde-Makefile\n, which runs the autograder on the autograding image when each submission is graded.\n\n\nFor the Hello Lab, \nautograde.tar\n is simply a copy of the \nhello-handout.tar\n file that is handed out to students. And here is the corresponding \n\nhello/autograde-makefile\n:\n\n\n1\n2\n3\n4\n5\n6\n7\nall\n:\n\n    \ntar\n \nxvf\n \nautograde\n.\ntar\n\n    \ncp\n \nhello\n.\nc\n \nhello\n-\nhandout\n\n    \n(\ncd\n \nhello\n-\nhandout\n;\n \n./\ndriver\n.\nsh\n)\n\n\n\nclean\n:\n\n    \nrm\n \n-\nrf\n \n*~\n \nhello\n-\nhandout\n\n\n\n\n\n\n\nThe makefile expands \nautograde.tar\n into \nhello-handout\n, copies \nhello.c\n (the submission file) into \nhello-handout\n, changes directory to \nhello-handout\n, builds the autograder, and then runs it. \n\n\nTest Directory\n\n\nFor our labs, we like to setup a test directory (called \ntest-autograder\n in this example), that allows us to test our \nautograde-Makefile\n and \nautograde-tar\n files by simulating Autolab's behavior on the autograding instance. The \ntest-autograder\n directory has the following form:\n\n\n1\n2\n3\n4\n5\n6\n$\n \ncd\n \ntest\n-\nautograder\n\n\n$\n \nls\n \n-\nl\n\n\n# total 3\n\n\n# lrwxr-xr-x 1 droh users  21 Aug  4 16:43 Makefile -\n ../autograde-Makefile\n\n\n# lrwxr-xr-x 1 droh users  16 Aug  4 16:43 autograde.tar -\n ../autograde.tar\n\n\n# -rw-rw-r-- 1 droh users 113 Aug  4 16:44 hello.c\n\n\n\n\n\n\n\nTo simulate Autolab's behavior on an autograding instance:\n\n\n1\n2\n3\n4\n5\n$\n \ncd\n \ntest\n-\nautograder\n \n \nmake\n \nclean\n \n \nmake\n\n\n# Running ./hello\n\n\n# Hello, world\n\n\n# Success: ./hello runs with an exit status of 0\n\n\n# {\nscores\n: {\nCorrectness\n: 100}}\n\n\n\n\n\n\n\nWriteup directory\n\n\nThe \nhello/writeup\n contains the detailed lab writeup, either html or pdf file, that students can download from the Autolab front end.", 
            "title": "Guide for Lab Authors"
        }, 
        {
            "location": "/lab/#writing-autograders", 
            "text": "An  autograder  is a program that takes a student's work as input, and generates some quantitative evaluation of that work as output. The student's work consists of one or more source files written in an arbitrary programming language. \nThe autograder processes these files and generates arbitrary text lines on stdout. The last text line on stdout must be a JSON string, called an  autoresult , that assigns an autograded score to one or more problems, and optionally, generates the scoreboard entries for this submission.  The JSON autoresult is a \"scores\" hash that assigns a numerical score to one or more problems, and an optional \"scoreboard\" array that provides the scoreboard entries for this submission. For example,   1 { scores : { Prob1 : 10,  Prob2 : 5}}   assigns 10 points to \"Prob1\" and 5 points to \"Prob2\" for this submission. The names of the problems must exactly match the names of the problems for this lab on the Autolab web site. Not all problems need to be autograded. For example, there might be a problem for this assessment called \"Style\" that you grade manually after the due date.   If you used the Autolab web site to configure a scoreboard for this lab with three columns called \"Prob1\", \"Prob2\", and \"Total\", then the autoresult might be:   1 { scores : { Prob1 : 10,  Prob2 : 5},  scoreboard : [10, 5, 15]}   By convention, an autograder accepts an optional  -A  command line argument that tells it to emit the JSON autoresult. So if you run the autograder outside of the context of Autolab, you can suppress the autoresult line by calling the autograder without the  -A  argument.  One of the nice properties of Autolab autograders is that they can be written and tested offline, without requiring any interaction with Autolab. Writing autograders is not easy, but the fact that they can be developed offline allows you to develop and test them in your own familiar computing environment.", 
            "title": "Writing Autograders"
        }, 
        {
            "location": "/lab/#installing-autograded-labs", 
            "text": "After you've written and tested the autograder, you then use the Autolab web site to create the autograded lab. Autolab supports creating new labs from scratch, or reusing labs from previous semesters. We'll describe each of these in turn.", 
            "title": "Installing Autograded Labs"
        }, 
        {
            "location": "/lab/#creating-an-autograded-lab-from-scratch", 
            "text": "", 
            "title": "Creating an Autograded Lab from Scratch"
        }, 
        {
            "location": "/lab/#step-1-create-the-new-lab", 
            "text": "Create a new lab by clicking the \"Install Assessment\" button and choosing \"Option 1: Create a New Assessment from Scratch.\" For course  course  and lab  lab ,  this will create a  lab directory  in the Autolab file hierarchy called  courses/ course / lab . This initial directory contains a couple of config files and a directory called  lab /handin  that will contain all of the student handin files. In general, you should never modify any of these.    Attention CMU Lab Authors  At CMU, the lab directory is called  /afs/cs/academic/class/ course /autolab/ lab . For example:  /afs/cs/academic/class/15213-f16/autolab/foo  is the lab directory for the lab named  foo  for the Fall 2016 instance of 15-213. All lab-related files must go in this  autolab  directory to avoid permissions issues.", 
            "title": "Step 1: Create the new lab."
        }, 
        {
            "location": "/lab/#step-2-configure-the-lab-for-autograding", 
            "text": "Using the \"Edit Assessment\" page, turn on autograding for this lab by selecting \"Add Autograder.\" You will be asked for the name of the image to be used for autograding this lab. The default image distributed with Autolab is an Ubuntu image called  autograding_image . If your class needs different software, then you or your facilities staff will need to update the default image or create a new one.    Attention CMU Lab Authors  The default autograding image at CMU is called  rhel.img  and is a copy of the software on the CMU Andrew machines ( linux.andrew.cmu.edu ). If you need custom software installed, please send mail to autolab-help@andrew.cmu.edu.   If you want a scoreboard, you should select \"Add Scoreboard,\" which will allow you to specify the number of columns and their names. The \"Add Scoreboard\" page contains a tutorial on how to do this.   You'll also need to define the names and point values for all the problems in this lab, including the autograded ones.   Each student submission is a single file, either a text source file or an archive file containing multiple files and directories. You'll need to specify the  base name  for the student submission files (e.g.,  mm.c ,  handin.tar ).", 
            "title": "Step 2: Configure the lab for autograding."
        }, 
        {
            "location": "/lab/#step-3-add-the-required-autograding-files", 
            "text": "For an autograded lab, Autolab expects the following two  autograding files  in the lab directory:    autograde-Makefile : runs the autograder on a student submission.  autograde.tar : contains all of the files (except for the student handin file) that are needed for autograding.    Each time a student submits their work or an instructor requests a regrade, Autolab    copies the student handin file, along with the two autograding files, to an empty directory on an  autograding instance ,   renames the student handin file to  base name  (e.g., hello.c, handin.tar),   renames  autograde-Makefile  to  Makefile ,   executes the command  make  on the autograding instance, and finally   captures the stdout generated by the autograder, and parses the resulting JSON autoresult to determine the autograded scores.", 
            "title": "Step 3: Add the required autograding files."
        }, 
        {
            "location": "/lab/#importing-an-autograded-lab-from-a-previous-semester", 
            "text": "If you've created a lab for a course in a previous semester and have access to the lab directory (as we do at CMU via AFS), you can import the lab into your current course by    copying the lab directory from the previous course to the current course,   cleaning out the  handin  directory, then   visiting the \"Install Assessment\" page and selecting \"Option 2: Import an existing assessment from the file system.\" Autolab will give you a list of all of the directories that appear to be uninstalled labs, from which you can select your particular lab.    If you don't have access to the lab directory, another option is to import a lab from a tarball that was created by running \"Export assessment\" in an instance of a lab from a previous semester. Visit the \"Install Assessment\" page and select \"Option 3: Import an existing assessment from tarball.\" This will upload the tarball, create a new lab directory by expanding the tarball, and then import the directory.", 
            "title": "Importing an Autograded Lab from a Previous Semester"
        }, 
        {
            "location": "/lab/#example-hello-lab", 
            "text": "In this section we'll look at the simplest possible autograded lab we could imagine, called, appropriately enough, the Hello Lab  \n(with  tarball ), which is stored in a lab directory called  hello  in the Autolab github repo. While it's trivial, it illustrates all of the aspects of developing an autograded lab, and provides a simple example that you can use for sanity testing on your Autolab installation.  In this lab, students are asked to write a version of the K R \"hello, world\" program, called  hello.c . The autograder simply checks that the submitted  hello.c  program compiles and runs with an exit status of zero. If so, the submission gets 100 points. Otherwise it gets 0 points.", 
            "title": "Example: Hello Lab"
        }, 
        {
            "location": "/lab/#directory-structure", 
            "text": "Autolab expects to find the  autograde-Makefile and  autograde.tar  files in the  hello  lab directory, but otherwise places no constraints on the contents and organization of this directory. However, based on our experience, we strongly recommend a directory structure with the following form:  hello/README :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 # Basic files created by the lab author\nMakefile                Builds the lab from src/\nREADME                  \nautograde-Makefile      Makefile that runs the autograder \nsrc/                    Contains all src files and solutions         \ntest-autograder/        For testing autograder offline\nwriteup/                Lab writeup that students view from Autolab    \n\n# Files created by running make\nhello-handout/          The directory that is handed out to students, created\n                        using files from src/. \nhello-handout.tar       Archive of hello-handout directory\nautograde.tar           File that is copied to the autograding instance \n                        (along with autograde-Makefile and student handin file)\n\n# Files created and managed by Autolab\nhandin/    All students handin files\nhello.rb   Config file\nhello.yml  Database properties that persist from semester to semester\nlog.txt    Log of autograded submissions   The key idea with this directory structure is to place  all  code for the lab in the  src  directory, including the autograding code and any starter code handed out to students in the handout directory ( hello-handout.tar  in this example). Keeping all hard state in the  src  directory helps limit inconsistencies.   The main makefile creates  hello-handout  by copying files from  src , and then tars it up:  hello/Makefile :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43 #  # Makefile to manage the example Hello Lab  #  # Get the name of the lab directory  LAB   =   $( notdir  $( PWD ))  all :   handout   handout - tarfile  handout :       # Rebuild the handout directory that students download \n     ( rm -rf  $( LAB ) -handout ;  mkdir  $( LAB ) -handout ) \n    cp -p src/Makefile-handout  $( LAB ) -handout/Makefile\n    cp -p src/README-handout  $( LAB ) -handout/README\n    cp -p src/hello.c-handout  $( LAB ) -handout/hello.c \n    cp -p src/driver.sh  $( LAB ) -handout handout-tarfile :   handout      # Build *-handout.tar and autograde.tar \n    tar cvf  $( LAB ) -handout.tar  $( LAB ) -handout\n    cp -p  $( LAB ) -handout.tar autograde.tar clean :      # Clean the entire lab directory tree.  Note that you can run      #  make clean; make  at any time while the lab is live with no      # adverse effects. \n    rm -f *~ *.tar\n     ( cd  src ;  make clean ) \n     ( cd  test-autograder ;  make clean ) \n    rm -rf  $( LAB ) -handout\n    rm -f autograde.tar #  # CAREFULL!!! This will delete all student records in the logfile and  # in the handin directory. Don t run this once the lab has started.  # Use it to clean the directory when you are starting a new version  # of the lab from scratch, or when you are debugging the lab prior  # to releasing it to the students.  #  cleanallfiles :      # Reset the lab from scratch. \n    make clean\n    rm -f log.txt\n    rm -rf handin/*   Filenames are disambiguated by appending  -handout , which is stripped when they are copied to the handout directory. For example,  src/hello.c  is the instructor's solution file, and  src/hello.c-handout  is the starter code that is given to the students in  hello-handout/hello.c . And  src/README  is the README for the src directory and  src/README-handout  is the README that is handed out to students in  hello-handout/README .  To build the lab, type  make clean; make . You can do this as often as you like while the lab is live with no adverse effects. However, be careful to never type  make cleanallfiles  while the lab is live; this should only be done before the lab goes live; never during or after.", 
            "title": "Directory Structure"
        }, 
        {
            "location": "/lab/#source-directory", 
            "text": "The  hello/src/  directory \ncontains  all  of the code files for the Hello Lab, including the files that are handed out to students:  hello/src/README :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 # Autograder and solution files\nMakefile                Makefile and ...\nREADME                  ... README for this directory\ndriver.sh*              Autograder\nhello.c                 Solution hello.c file\n\n# Files that are handed out to students\nMakefile-handout        Makefile and ...\nREADME-handout          ... README handed out to students\nhello.c-handout         Blank hello.c file handed out to students", 
            "title": "Source Directory"
        }, 
        {
            "location": "/lab/#handout-directory", 
            "text": "The  hello/hello-handout/  directory\ncontains the files that the students will use to work on the lab. It contains no hard state, and is populated entirely with files from  hello/src :  hello/hello-handout/README :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 For   this   lab ,   you   should   write   a   tiny   C   program ,   called   hello.c ,  that   prints   hello, world   to   stdout   and   then   indicates   success   by  exiting   with   a   status   of   zero .  To   test   your   work :   $   make   clean ;   make ;   ./ hello  To   run   the   same   autograder   that   Autolab   will   use   when   you   submit :  $   ./ driver . sh  Files :  README            This   file  Makefile          Compiles   hello . c  driver . sh         Autolab   autograder  hello . c           Empty   C   file   that   you   will   edit    hello/hello-handout/Makefile  contains the rules that compile the student source code:  1\n2\n3\n4\n5\n6 # Student makefile for the Hello Lab \nall: \n    gcc hello.c -o hello\n\nclean:\n    rm -rf *~ hello   To compile and run their code, students type:  1\n2 $   make   clean ;   make  $   ./ hello", 
            "title": "Handout Directory"
        }, 
        {
            "location": "/lab/#autograder", 
            "text": "The autograder for the Hello Lab is a trivially simple bash script called  driver.sh  that compiles and runs  hello.c  and verifies that it returns with an exit status of zero:  hello/src/driver.sh     1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30 #!/bin/bash  # driver.sh - The simplest autograder we could think of. It checks  #   that students can write a C program that compiles, and then  #   executes with an exit status of zero.  #   Usage: ./driver.sh  # Compile the code  echo   Compiling hello.c  ( make clean ;  make )  status = $?  if   [   ${ status }  -ne  0   ] ;   then \n     echo   Failure: Unable to compile hello.c (return status =  ${ status } ) \n     echo   {\\ scores\\ : {\\ Correctness\\ : 0}} \n     exit  fi  # Run the code  echo   Running ./hello \n./hello status = $?  if   [   ${ status }  -eq  0   ] ;   then \n     echo   Success: ./hello runs with an exit status of 0 \n     echo   {\\ scores\\ : {\\ Correctness\\ : 100}}  else \n     echo   Failure: ./hello fails or returns nonzero exit status of  ${ status } \n     echo   {\\ scores\\ : {\\ Correctness\\ : 0}}  fi  exit    For example:  1\n2\n3\n4\n5\n6\n7\n8 $   ./ driver . sh  # Compiling hello.c  # rm -rf *~ hello  # gcc hello.c -o hello  # Running ./hello  # Hello, world  # Success: ./hello runs with an exit status of 0  # { scores : { Correctness : 100}}    Notice that the autograder expects the  hello  lab on the Autolab front-end to have been defined with a problem called \"Correctness\", with a maximum value of 100 points. If you forget to define the problems listed in the JSON autoresult, scores will still be logged, but they won't be posted to the database.", 
            "title": "Autograder"
        }, 
        {
            "location": "/lab/#required-autograding-files", 
            "text": "Autolab requires two  autograding files  called  autograde.tar , which contains all of the code required by the autograder, and  autograde-Makefile , which runs the autograder on the autograding image when each submission is graded.  For the Hello Lab,  autograde.tar  is simply a copy of the  hello-handout.tar  file that is handed out to students. And here is the corresponding  hello/autograde-makefile :  1\n2\n3\n4\n5\n6\n7 all : \n     tar   xvf   autograde . tar \n     cp   hello . c   hello - handout \n     ( cd   hello - handout ;   ./ driver . sh )  clean : \n     rm   - rf   *~   hello - handout    The makefile expands  autograde.tar  into  hello-handout , copies  hello.c  (the submission file) into  hello-handout , changes directory to  hello-handout , builds the autograder, and then runs it.", 
            "title": "Required Autograding Files"
        }, 
        {
            "location": "/lab/#test-directory", 
            "text": "For our labs, we like to setup a test directory (called  test-autograder  in this example), that allows us to test our  autograde-Makefile  and  autograde-tar  files by simulating Autolab's behavior on the autograding instance. The  test-autograder  directory has the following form:  1\n2\n3\n4\n5\n6 $   cd   test - autograder  $   ls   - l  # total 3  # lrwxr-xr-x 1 droh users  21 Aug  4 16:43 Makefile -  ../autograde-Makefile  # lrwxr-xr-x 1 droh users  16 Aug  4 16:43 autograde.tar -  ../autograde.tar  # -rw-rw-r-- 1 droh users 113 Aug  4 16:44 hello.c    To simulate Autolab's behavior on an autograding instance:  1\n2\n3\n4\n5 $   cd   test - autograder     make   clean     make  # Running ./hello  # Hello, world  # Success: ./hello runs with an exit status of 0  # { scores : { Correctness : 100}}", 
            "title": "Test Directory"
        }, 
        {
            "location": "/lab/#writeup-directory", 
            "text": "The  hello/writeup  contains the detailed lab writeup, either html or pdf file, that students can download from the Autolab front end.", 
            "title": "Writeup directory"
        }
    ]
}